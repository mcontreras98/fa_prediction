{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import statistics\n",
    "from scipy.stats import pearsonr\n",
    "from PIL import Image\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-honor",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'E:/allen'\n",
    "data_class = os.listdir(data_dir)\n",
    "test_dir = 'E:/cgan/model/enc/imgs_unet_guide_test'\n",
    "class_dir = os.listdir(test_dir)\n",
    "num_examples = []\n",
    "for protein in data_class:\n",
    "    protein_folder = os.path.join(data_dir, protein)\n",
    "    num_examples.append(len(os.listdir(protein_folder)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-mercury",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "mean_pearson = []\n",
    "mean_rmse = []\n",
    "total_examples = []\n",
    "training_examples = []\n",
    "test_examples = []\n",
    "for folder in class_dir:\n",
    "    class_folder = os.path.join(test_dir, folder)\n",
    "    print('{}: {}'.format(folder, data_class[count]))\n",
    "    pearson_scores = []\n",
    "    rmse_scores = []\n",
    "    for filename in os.listdir(class_folder):\n",
    "        img_folder = os.path.join(class_folder, filename)\n",
    "        for image in os.listdir(img_folder):\n",
    "            if image == 'ground_truth.png':\n",
    "                ground_truth_path = os.path.join(img_folder, image)\n",
    "                ground_truth = Image.open(ground_truth_path)\n",
    "                ground_truth = np.asarray(ground_truth)\n",
    "                prot_truth = ground_truth[:,:,1]\n",
    "                res = np.zeros((256, 256, 3))\n",
    "                res[:,:,1] = ground_truth[:,:,1]\n",
    "                prot_truth = prot_truth.flatten()\n",
    "            elif image == 'prediction.png':\n",
    "                prediction_path = os.path.join(img_folder, image)\n",
    "                prediction = Image.open(prediction_path)\n",
    "                prediction = np.asarray(prediction)\n",
    "                prot_pred = prediction[:,:,1]\n",
    "                prot_pred = prot_pred.flatten()\n",
    "        pearson_value = pearsonr(prot_truth, prot_pred)\n",
    "        pearson_scores.append(pearson_value[0])\n",
    "        rmse = mean_squared_error(prot_truth, prot_pred, squared=False)\n",
    "        rmse_scores.append(rmse)\n",
    "    mean_pearson.append(statistics.mean(pearson_scores))\n",
    "    mean_rmse.append(statistics.mean(rmse_scores))\n",
    "    total_examples.append(num_examples[count])\n",
    "    training_examples.append(num_examples[count] - len(os.listdir(class_folder)))\n",
    "    test_examples.append(len(os.listdir(class_folder)))\n",
    "    print('----Statistics----')\n",
    "    print('Average of Pearson Correlation: {}'.format(statistics.mean(pearson_scores)))\n",
    "    print('Standard Deviation of Pearson Correlation: {}'.format(statistics.stdev(pearson_scores)))\n",
    "    print('Median of Pearson Correlation: {}'.format(statistics.median(pearson_scores)))\n",
    "    print('Average of RMSE: {}'.format(statistics.mean(rmse_scores)))\n",
    "    print('Standard Deviation of RMSE: {}'.format(statistics.stdev(rmse_scores)))\n",
    "    print('----Data----')\n",
    "    print('Total Number of Examples: {}'.format(num_examples[count]))\n",
    "    print('Number of Training Examples: {}'.format(num_examples[count] - len(os.listdir(class_folder))))\n",
    "    print('Number of Test Examples: {}'.format(len(os.listdir(class_folder))))\n",
    "    print('%'*40)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-nature",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('data.csv', 'w', newline='') as csvfile:\n",
    "    datawriter = csv.writer(csvfile, delimiter=',',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    datawriter.writerow([data_class[i] for i in range(10)])\n",
    "    datawriter.writerow([class_dir[i] for i in range(10)])\n",
    "    datawriter.writerow([mean_pearson[i] for i in range(10)])\n",
    "    datawriter.writerow([mean_rmse[i] for i in range(10)])\n",
    "    datawriter.writerow([total_examples[i] for i in range(10)])\n",
    "    datawriter.writerow([training_examples[i] for i in range(10)])\n",
    "    datawriter.writerow([test_examples[i] for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-banking",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
